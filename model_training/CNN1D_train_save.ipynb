{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.utils import np_utils\n",
    "import time\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6gbmprmhGiPI"
   },
   "outputs": [],
   "source": [
    "def load_train_Data( relay = 'RTL3'):\n",
    "    os.chdir('../Data')\n",
    "    data1 = sio.loadmat(relay + '.mat')['C1'+ relay]\n",
    "    data1[:,1:7] = (data1[:,1:7] - data1[:,1:7].min(axis=0)) / (data1[:,1:7].max(axis=0)- data1[:,1:7].min(axis=0))\n",
    "    data2 = sio.loadmat(relay + '.mat')['C2'+ relay]\n",
    "    data2[:,1:7] = (data2[:,1:7] - data2[:,1:7].min(axis=0)) / (data2[:,1:7].max(axis=0)- data2[:,1:7].min(axis=0))\n",
    "    data3 = sio.loadmat(relay + '.mat')['C3'+ relay]\n",
    "    data3[:,1:7] = (data3[:,1:7] - data3[:,1:7].min(axis=0)) / (data3[:,1:7].max(axis=0)- data3[:,1:7].min(axis=0))\n",
    "    data4 = sio.loadmat(relay + '.mat')['C4'+ relay]\n",
    "    data4[:,1:7] = (data4[:,1:7] - data4[:,1:7].min(axis=0)) / (data4[:,1:7].max(axis=0)- data4[:,1:7].min(axis=0))\n",
    "\n",
    "    return data1, data2, data3, data4\n",
    "\n",
    "def convert_to_3d(data,n_time=100):\n",
    "    a1 = int(np.floor(data.shape[0]/n_time)*n_time)\n",
    "    data = data[:a1,:]\n",
    "    n_feat = data.shape[1]\n",
    "    X1 = data.reshape((round(data.shape[0]/n_time),n_time,n_feat))\n",
    "    X11 = X1[:,:,1:7]\n",
    "    Y11 = X1[:,0,11]\n",
    "    return X11, Y11\n",
    "\n",
    "def data_preparation(data1, data2, data3, data4):\n",
    "    [data11, lab1] = convert_to_3d(data1) # organizing into a 3d data with time frames\n",
    "    [data22, lab2] = convert_to_3d(data2)\n",
    "    [data33, lab3] = convert_to_3d(data3)\n",
    "    [data44, lab4] = convert_to_3d(data4)\n",
    "    #print(data11.shape, lab1.shape, data22.shape, lab2.shape, data33.shape, lab3.shape, data44.shape, lab4.shape)\n",
    "\n",
    "    train1 = data11[0:round(data11.shape[0]/2),:,:]\n",
    "    lab_train1 = lab1[0:round(data11.shape[0]/2)]\n",
    "    test1 = data11[round(data11.shape[0]/2):,:,:]\n",
    "    lab_test1 = lab1[round(data11.shape[0]/2):]\n",
    "\n",
    "    train2 = data22[0:round(data22.shape[0]/2),:,:]\n",
    "    lab_train2 = lab2[0:round(data22.shape[0]/2)]\n",
    "    test2 = data22[round(data22.shape[0]/2):,:,:]\n",
    "    lab_test2 = lab2[round(data22.shape[0]/2):]\n",
    "\n",
    "    train3 = data33[0:round(data33.shape[0]/2),:,:]\n",
    "    lab_train3 = lab3[0:round(data33.shape[0]/2)]\n",
    "    test3 = data33[round(data33.shape[0]/2):,:,:]\n",
    "    lab_test3 = lab3[round(data33.shape[0]/2):]\n",
    "\n",
    "    train4 = data44[0:round(data44.shape[0]/2),:,:]\n",
    "    lab_train4 = lab4[0:round(data44.shape[0]/2)]\n",
    "    test4 = data44[round(data44.shape[0]/2):,:,:]\n",
    "    lab_test4 = lab4[round(data44.shape[0]/2):]\n",
    "\n",
    "    #print(train1.shape, lab_train1.shape, train2.shape, lab_train2.shape, train3.shape, lab_train3.shape, train4.shape, lab_train4.shape)\n",
    "    #print(test1.shape, lab_test1.shape, test2.shape, lab_test2.shape, test3.shape, lab_test3.shape, test4.shape, lab_test4.shape)\n",
    "    X_train = np.concatenate((train1,train2,train3,train4),axis = 0)\n",
    "    Y_train = np.concatenate((lab_train1,lab_train2,lab_train3,lab_train4),axis = 0)\n",
    "    x_test_orig =  np.concatenate((test1,test2,test3,test4),axis = 0)\n",
    "    y_test_orig = np.concatenate((lab_test1,lab_test2,lab_test3,lab_test4),axis = 0)\n",
    "\n",
    "    return X_train, Y_train, x_test_orig, y_test_orig\n",
    "\n",
    "def convert_tocategorical(y, number_of_classes=4):\n",
    "    y_conv = np_utils.to_categorical(y.ravel()-1, number_of_classes)\n",
    "    return y_conv\n",
    "\n",
    "  # fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy):#, X_val, y_val):\n",
    "    verbose, epochs, batch_size = 0, 1, 32\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model1 = model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose = 0)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose = 0)\n",
    "    return accuracy, model, model1\n",
    "\n",
    "# summarize scores\n",
    "def summarize_results(scores):\n",
    "    print(scores)\n",
    "    m, s = np.mean(scores), np.std(scores)\n",
    "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
    " \n",
    "    # run an experiment\n",
    "\n",
    "def run_experiment(X_train, Y_train,X_test, Y_test,repeats=10):\n",
    "    # load data\n",
    "    trainX = X_train\n",
    "    trainy = Y_train\n",
    "    testX = X_test\n",
    "    testy = Y_test\n",
    "    max_acc = 0\n",
    "    # Split the dataset in two equal parts\n",
    "    #X_train, X_val, Y_train, y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=0)\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        [score, model, model1] = evaluate_model(trainX, trainy, testX, testy)#, X_val, y_val)\n",
    "        score = score * 100.0\n",
    "        print('>#%d: %.3f' % (r+1, score))\n",
    "        scores.append(score)\n",
    "        if score > max_acc:\n",
    "            best_model = model\n",
    "            max_acc = score\n",
    "        # summarize results\n",
    "    summarize_results(scores)\n",
    "    return scores, best_model, max_acc, model1, model\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,normalize=False,title='Confusion matrix',cmap=plt.cm.Purples):\n",
    "  \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm = np.around(cm*100, decimals=2)\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        plt.title(title)\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        plt.xticks(tick_marks, classes, rotation=45)\n",
    "        plt.yticks(tick_marks, classes)\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        plt.title(title)\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        plt.xticks(tick_marks, classes, rotation=45)\n",
    "        plt.yticks(tick_marks, classes)\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def perf_measure(y_actual, y_hat):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "            TP += 1\n",
    "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "            FP += 1\n",
    "        if y_actual[i]==y_hat[i]==0:\n",
    "            TN += 1\n",
    "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "            FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YLluVxI5IJHZ"
   },
   "outputs": [],
   "source": [
    "relay = 'RTL3'\n",
    "[data1, data2, data3, data4] = load_train_Data(relay)\n",
    "[X_train, ytrain, X_test, ytest] = data_preparation(data1, data2, data3, data4)\n",
    "Y_train = convert_tocategorical(ytrain, 4)\n",
    "Y_test = convert_tocategorical(ytest, 4)\n",
    "start = time.time()\n",
    "[scores, best_model, max_acc, model1, model] = run_experiment(X_train, Y_train, X_test, Y_test)\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "Y_pred = best_model.predict(X_test, verbose=2)\n",
    "#Y_pred.shape\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "for ix in range(4):\n",
    "    print(ix, confusion_matrix(np.argmax(Y_test,axis=1),y_pred)[ix].sum())\n",
    "cm = confusion_matrix(np.argmax(Y_test,axis=1),y_pred)\n",
    "print(cm)\n",
    "scores = np.array(scores)/100\n",
    "cnn = model1\n",
    "\n",
    "f2 = plt.figure(0)\n",
    "plt.plot(cnn.history['accuracy'],'r')\n",
    "plt.plot(scores,'g')\n",
    "plt.xticks(np.arange(0, 11, 2.0))\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.xlabel(\"Num of Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training Accuracy vs Validation Accuracy\")\n",
    "plt.legend(['train','validation'])\n",
    "f2.savefig(\"accuracy.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "[TP, FP, TN, FN] = perf_measure(np.argmax(Y_test,axis=1),y_pred)\n",
    "print(TP, FP, TN, FN)\n",
    "\n",
    "p_detect = TP/(TP+FN)\n",
    "p_false = FP/(TN+FN)\n",
    "print(p_detect, p_false)\n",
    "\n",
    "############ PLOT CONFUSION MATRIX (TEST) ############################\n",
    "target_names = ['Config1', 'Config2', 'Config3', 'Config4']\n",
    "np.set_printoptions(precision=2)\n",
    "cnf_matrix = cm\n",
    "print(max_acc)\n",
    "print(p_detect, p_false)\n",
    "class_names = target_names\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "os.chdir('../Models')\n",
    "best_model.save_weights(\"CNN_weights_RTL3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPleQwrUFlFYe5xVXPhwpyd",
   "collapsed_sections": [],
   "mount_file_id": "1FELRPmFKWoJxpvOaKmqKRnvSON-hPd_E",
   "name": "CNN1D_train_save.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
