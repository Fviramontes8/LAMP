{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UilzJIgBch4G",
    "outputId": "28437d34-ee03-491d-f911-ea2b39a7e38c"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import svm\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iDwlKrwBcXCS"
   },
   "outputs": [],
   "source": [
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.LinearKernel(variance_prior = gpytorch.priors.GammaPrior(2,2)))#gpytorch.kernels.ScaleKernel(gpytorch.kernels.LinearKernel(variance_prior = gpytorch.priors.GammaPrior(0.5,2)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "def GP_model(train_x, train_y):\n",
    "  \n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "\n",
    "    hypers = {\n",
    "      'likelihood.noise_covar.noise': torch.tensor(1.),\n",
    "      'covar_module.outputscale': torch.tensor(2.),\n",
    "    }\n",
    "\n",
    "    model = ExactGPModel(train_x, train_y, likelihood)\n",
    "    model.initialize(**hypers)\n",
    "    #print(\n",
    "    #  model.likelihood.noise_covar.noise.item(),\n",
    "    #   model.covar_module.outputscale.item()\n",
    "    #)\n",
    "\n",
    "    #print(model.named_parameters)\n",
    "    #for param_name, param in model.named_parameters():\n",
    "    # print(f'Parameter name: {param_name:42} value = {param.item()}')\n",
    "\n",
    "    return model, likelihood\n",
    "\n",
    "\n",
    "def GP_train(train_x, train_y, n_iter=2000):\n",
    "    [model, likelihood] = GP_model(train_x, train_y)\n",
    "\n",
    "    smoke_test = ('CI' in os.environ)\n",
    "    training_iter = 2 if smoke_test else n_iter\n",
    "    model = model.double()\n",
    "\n",
    "    # Find optimal model hyperparameters\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    # Use the adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "    l= np.zeros((training_iter,1))\n",
    "    for i in range(training_iter):\n",
    "        # Zero gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        # Output from model\n",
    "        output = model(train_x)\n",
    "        # Calc loss and backprop gradients\n",
    "        loss = -mll(output, train_y)\n",
    "        loss.backward()\n",
    "        l[i] = loss.item()\n",
    "        #print('Iter %d/%d - Loss: %.3f   noise: %.3f' % (\n",
    "         # i + 1, training_iter, loss.item(),\n",
    "         # model.likelihood.noise.item()\n",
    "        #))\n",
    "        optimizer.step()\n",
    "\n",
    "    return model, likelihood, l\n",
    "\n",
    "def Gp_test(test_x, model, likelihood):\n",
    "\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "\n",
    "\n",
    "    # Test points are regularly spaced along [0,1]\n",
    "    # Make predictions by feeding model through likelihood\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        #observed_pred = model(test_x)\n",
    "        observed_pred = likelihood(model(test_x))\n",
    "        f_var = observed_pred.variance\n",
    "\n",
    "    return observed_pred, f_var\n",
    "\n",
    "\n",
    "def plot_test_GP(observed_pred, f_var, test_y):\n",
    "\n",
    "    n_sample0 = 0\n",
    "    n_sample1 = test_y.shape[0]\n",
    "  \n",
    "    with torch.no_grad():\n",
    "    # Initialize plot\n",
    "    # Get upper and lower confidence bounds\n",
    "    #lower, upper = observed_pred.confidence_region()\n",
    "        mae = mean_absolute_error(test_y.numpy(), observed_pred.mean.numpy())\n",
    "        mse = mean_squared_error(test_y.numpy(), observed_pred.mean.numpy())\n",
    "        mse_var = mean_squared_error(test_y.numpy(), observed_pred.mean.numpy())/np.var(test_y.numpy(), axis=0)\n",
    "        lower = observed_pred.mean-2*f_var\n",
    "        upper = observed_pred.mean+2*f_var\n",
    "        error1 = observed_pred.mean.numpy()[n_sample0:n_sample1] - test_y.numpy()[n_sample0:n_sample1]\n",
    "    return error1, f_var\n",
    "\n",
    "def probability_SC(true, pred):\n",
    "    '''\n",
    "    returns the probability of detection\n",
    "    and probability of false alarm\n",
    "    '''\n",
    "    cm = confusion_matrix(true, pred)\n",
    "    pdetect = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "    pfalse = cm[1,0]/(cm[1,0]+cm[1,1])\n",
    "\n",
    "    return cm, pdetect, pfalse\n",
    "\n",
    "def pdtect_vs_pfalse_swipe(scores_oc, y_true, step):\n",
    "    threshold = []\n",
    "    p_detect = []\n",
    "    p_false = []\n",
    "    cmat = []\n",
    "    for thresh in np.arange(min(scores_oc),max(scores_oc)+0.01,step):\n",
    "        y_pred = 2*(scores_oc > thresh)- 1\n",
    "        [cm, pd, pf] = probability_SC(y_true, y_pred)\n",
    "        threshold.append(thresh)\n",
    "        p_detect.append(pd)\n",
    "        p_false.append(pf)\n",
    "        cmat.append(cm)\n",
    "    return p_detect, p_false, threshold, cmat\n",
    "\n",
    "def OCSVM_train(train):\n",
    "  \n",
    "    clf = svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1)\n",
    "    clf.fit(train)\n",
    "\n",
    "    return clf\n",
    "\n",
    "def OCSVM_test(clf, test, test_lab):\n",
    "    pred = clf.predict(test)\n",
    "    scores_oc = clf.decision_function(test)\n",
    "    p = 1/(1+np.exp(scores_oc))\n",
    "\n",
    "\n",
    "    return pred, scores_oc, p\n",
    "  \n",
    "def swipe_plot(scores_oc, test_lab, step):\n",
    "    [pdetect_s, pfalse_s, thresh_s, cmat] = pdtect_vs_pfalse_swipe(scores_oc, test_lab, step)\n",
    "    plt.plot(pfalse_s, 1-np.array(pdetect_s),'.')\n",
    "    plt.xlabel('PFA')\n",
    "    plt.ylabel('1-PD')\n",
    "    plt.grid()\n",
    "\n",
    "def GP_plus_OC_TRAIN(train_x, train_y,  train_iter,  tr_switch):\n",
    "  \n",
    "    train_x = torch.from_numpy(train_x)\n",
    "    train_y = torch.from_numpy(train_y)\n",
    "    \n",
    "    ########### TRAIN ######################\n",
    "    # GP1 train \n",
    "    [model1, likelihood1, loss1] = GP_train(train_x.double(),train_y[:,0].double(), train_iter)\n",
    "    [observed_pred11, f_var11] = Gp_test(train_x.double(), model1, likelihood1)\n",
    "    [error11, f_var11] = plot_test_GP(observed_pred11, f_var11, train_y[:,0].double())\n",
    "    \n",
    "    # GP2 train\n",
    "    [model2, likelihood2, loss2] = GP_train(train_x.double(),train_y[:,1].double(), train_iter)\n",
    "    [observed_pred22, f_var22] = Gp_test(train_x.double(), model2, likelihood2)\n",
    "    [error22, f_var22] = plot_test_GP(observed_pred22, f_var22, train_y[:,1].double())\n",
    "    \n",
    "    # GP3 Train \n",
    "    [model3, likelihood3, loss3] = GP_train(train_x.double(),train_y[:,2].double(), train_iter)\n",
    "    [observed_pred33, f_var33] = Gp_test(train_x.double(), model3, likelihood3)\n",
    "    [error33, f_var33] = plot_test_GP(observed_pred33, f_var33, train_y[:,2].double())\n",
    "    \n",
    "    std_nf1 = np.sqrt(f_var11)\n",
    "    std_nf2 = np.sqrt(f_var22)\n",
    "    std_nf3 = np.sqrt(f_var33)\n",
    "    \n",
    "    train = np.vstack((error11/std_nf1,error22/std_nf2,error33/std_nf3)).T\n",
    "    \n",
    "    clf = OCSVM_train(train)\n",
    "    \n",
    "    return model1, model2, model3, clf\n",
    "    \n",
    "def GP_plus_OC_TEST(test_x, test_y, test_lab):\n",
    "    test_x = torch.from_numpy(test_x)\n",
    "    test_y = torch.from_numpy(test_y)\n",
    "    ##################### TEST #######################\n",
    "    #test GP1\n",
    "    [observed_pred1, f_var1] = Gp_test(test_x.double(), model1, likelihood1)\n",
    "    [error1, f_var1] = plot_test_GP(observed_pred1, f_var1, test_y[:,0].double())\n",
    "\n",
    "    \n",
    "    # test GP2\n",
    "    [observed_pred2, f_var2] = Gp_test(test_x.double(), model2, likelihood2)\n",
    "    [error2, f_var2] = plot_test_GP(observed_pred2, f_var2, test_y[:,1].double())\n",
    "\n",
    "    \n",
    "    # test GP3\n",
    "    [observed_pred3, f_var3] = Gp_test(test_x.double(), model3, likelihood3)\n",
    "    [error3, f_var3] = plot_test_GP(observed_pred3, f_var3, test_y[:,2].double())\n",
    "\n",
    "    std_f1 = np.sqrt(f_var1)\n",
    "    std_f2 = np.sqrt(f_var2)\n",
    "    std_f3 = np.sqrt(f_var3)\n",
    "    \n",
    "    test = np.vstack((error1/std_f1,error2/std_f2,error3/std_f3)).T\n",
    "\n",
    "    #print(train.shape, test.shape)\n",
    "    \n",
    "    [pred, scores_oc, p] = OCSVM_test(clf, test, test_lab)\n",
    "\n",
    "    return pred, scores_oc, p, test\n",
    "\n",
    "def loading_train_data(data1):\n",
    "    '''\n",
    "    Data loading code for loading the data for GP1, GP2, GP3\n",
    "    and testing data for the same\n",
    "    '''\n",
    "    j = 0\n",
    "    i = 2000\n",
    "    s = 20\n",
    "\n",
    "    train = data1[0:round(data1.shape[0]/2),:]\n",
    "    train_nf = train[np.where(train[:,10]==0)]\n",
    "    i1 = round(train_nf.shape[0]/2)\n",
    "    i0 = i1 - 100000\n",
    "    max1 = train_nf[i0:i1:s,1:7].max(axis=0)\n",
    "    min1 = train_nf[i0:i1:s,1:7].min(axis=0)\n",
    "    train_nf[i0:i1:s,1:7] = (train_nf[i0:i1:s,1:7] - min1) / (max1 - min1)\n",
    "    #print(min1, max1)\n",
    "    # train data\n",
    "    train_x = train_nf[i0:i1:s,1:4]\n",
    "    train_y = train_nf[i0:i1:s,4:7]   # for all GP\n",
    "    train_lab = train_nf[i0:i1:s,10]\n",
    "\n",
    "    return train_x, train_y, train_lab, [max1,min1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "dir_path = 'RTL3.mat'\n",
    "mat_file = 'C4RTL3' #train_sub:change these to all config based on the training config\n",
    "train_iter = 2000\n",
    "tr_switch = 1\n",
    "os.chdir('..\\Data')\n",
    "data1 = sio.loadmat(dir_path)[mat_file]\n",
    "train_x, train_y, train_lab, max_min_tr = loading_train_data(data1)\n",
    "\n",
    "[GP1, GP2, GP3, OCSVM] = GP_plus_OC_TRAIN(train_x, train_y,  train_iter,  tr_switch)\n",
    "\n",
    "#GP1.state_dict()\n",
    "#GP2.state_dict()\n",
    "#GP3.state_dict()\n",
    "\n",
    "os.chdir('..\\Models')\n",
    "\n",
    "torch.save(GP1.state_dict(), 'GP1_' + mat_file + '.pth')\n",
    "\n",
    "\n",
    "torch.save(GP2.state_dict(), 'GP2_' + mat_file + '.pth')\n",
    "\n",
    "\n",
    "torch.save(GP3.state_dict(), 'GP3_' + mat_file + '.pth')\n",
    "\n",
    "file_name = 'OCSVM_'+ mat_file + '.sav'\n",
    "pickle.dump(OCSVM, open(file_name, 'wb'))\n",
    "np.save('maxmin_GPOCSVM_' + mat_file + '.npy', max_min_tr)\n",
    "np.save('train_GP_' + mat_file + '.npy', [train_x,train_y])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of GP_OCSVM_simple.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
